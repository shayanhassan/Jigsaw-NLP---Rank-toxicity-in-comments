{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d653bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from time import time \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7447d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../../../jigsaw-toxic-severity-rating/validation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3f4a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2      \"Atom you don't believe actual photos of mastu...  \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4               hey \\n\\nway to support nazis, you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       Piss off you slant eyed-gook  \n",
       "30106                       Piss off you slant eyed-gook  \n",
       "30107                       Piss off you slant eyed-gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98c40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "def text_cleaning(text):\n",
    "    if text:\n",
    "        text = ' '.join(text.split('.'))\n",
    "        text = re.sub('\\/',' ',text)\n",
    "        text = re.sub(r'\\\\',' ',text)\n",
    "        text = re.sub(r'((http)\\S+)','',text)\n",
    "        text = re.sub(r'\\s+', ' ', re.sub('[^A-Za-z]', ' ', text.strip().lower())).strip()\n",
    "        text = re.sub(r'\\W+', ' ', text.strip().lower()).strip()\n",
    "        text = [word for word in text.split()]\n",
    "        return text\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822c9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "435bd62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(s):\n",
    "    l=s.split(\" \")\n",
    "    l2=[lemmatizer.lemmatize(word) for word in l]\n",
    "    s=\" \".join(l2)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "91825f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.less_toxic = df.less_toxic.apply(lambda x: ' '.join(text_cleaning(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2c960045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.less_toxic = df.less_toxic.apply(lambda x: lemmatizing(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc019326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>this article suck woo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>and yes people should recognize that but they ...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>western medium yup because every crime in the ...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>and you removed it you numbskull i don t care ...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina bluerasberry why don t you be a ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>i m sorry i m not an admin i will give you thr...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>i m sorry i m not an admin i will give you thr...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow are you out of your mind how wa my edit on...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow are you out of your mind how wa my edit on...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow are you out of your mind how wa my edit on...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313                 this article suck woo woo wooooooo   \n",
       "1         188  and yes people should recognize that but they ...   \n",
       "2          82  western medium yup because every crime in the ...   \n",
       "3         347  and you removed it you numbskull i don t care ...   \n",
       "4         539  smelly vagina bluerasberry why don t you be a ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  i m sorry i m not an admin i will give you thr...   \n",
       "30104     527  i m sorry i m not an admin i will give you thr...   \n",
       "30105     352  wow are you out of your mind how wa my edit on...   \n",
       "30106     311  wow are you out of your mind how wa my edit on...   \n",
       "30107      54  wow are you out of your mind how wa my edit on...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2      \"Atom you don't believe actual photos of mastu...  \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4               hey \\n\\nway to support nazis, you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       Piss off you slant eyed-gook  \n",
       "30106                       Piss off you slant eyed-gook  \n",
       "30107                       Piss off you slant eyed-gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd3a56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [word_tokenize(sent) for sent in df.less_toxic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "700f2961",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(sentences, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "73575c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eed4acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = bigram[sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ea89bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "w2v_model.build_vocab(sentences2, progress_per=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "92aee2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15971092, 64393050)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences2, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b6b06dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\AppData\\Local\\Temp/ipykernel_11228/514372312.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "eb2ea8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "40cc4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "438252a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = Word2Vec.load(\"word2vec.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c275c3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x27813f28490>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8d575ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "488d4952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('burp', 0.9661408066749573),\n",
       " ('spel', 0.9638698101043701),\n",
       " ('kant', 0.9608436226844788),\n",
       " ('bithces', 0.9570140242576599),\n",
       " ('fainted', 0.9564516544342041),\n",
       " ('thingggggggggggg', 0.9560933709144592),\n",
       " ('ik', 0.9541478753089905),\n",
       " ('charna', 0.9535954594612122),\n",
       " ('marissa', 0.952586829662323),\n",
       " ('wierddd', 0.951858401298523)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "173eec88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fourohfour', 0.9476852416992188),\n",
       " ('bail_out', 0.9469375610351562),\n",
       " ('hate_wikipedia', 0.9424804449081421),\n",
       " ('flabbergastingly', 0.9377520084381104),\n",
       " ('cuntt', 0.9334406852722168),\n",
       " ('vomit_vomit', 0.9327620267868042),\n",
       " ('nikko_smell', 0.932682454586029),\n",
       " ('jog', 0.9326014518737793),\n",
       " ('picture_showing', 0.932592511177063),\n",
       " ('making_love', 0.9322660565376282)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "f6abe071",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_index = 1\n",
    "positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
    "negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3374a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.index_to_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a3b1ecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25083</th>\n",
       "      <td>maliyadeva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25084</th>\n",
       "      <td>massless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25085</th>\n",
       "      <td>matara</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25086</th>\n",
       "      <td>suares</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25087</th>\n",
       "      <td>delusive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25088 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "0             the\n",
       "1               a\n",
       "2              to\n",
       "3             you\n",
       "4               i\n",
       "...           ...\n",
       "25083  maliyadeva\n",
       "25084    massless\n",
       "25085      matara\n",
       "25086      suares\n",
       "25087    delusive\n",
       "\n",
       "[25088 rows x 1 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "4cd64f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a32157e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6725d08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>[-0.04089157, -0.10525032, 0.06359307, 0.03510...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.030860</td>\n",
       "      <td>1.030860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>[-0.016692968, -0.13745366, 0.027092986, -0.02...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.046803</td>\n",
       "      <td>1.046803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>to</td>\n",
       "      <td>[-0.009316119, -0.12273791, 0.112017654, 0.009...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.070928</td>\n",
       "      <td>1.070928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>you</td>\n",
       "      <td>[0.01881397, 0.05734981, 0.17161769, 0.0083904...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.090952</td>\n",
       "      <td>1.090952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i</td>\n",
       "      <td>[-0.0049191266, 0.0117665185, 0.13627413, -0.0...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.099641</td>\n",
       "      <td>1.099641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25083</th>\n",
       "      <td>maliyadeva</td>\n",
       "      <td>[0.025441179, 0.050027493, -0.016706299, 0.047...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.584844</td>\n",
       "      <td>-1.584844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25084</th>\n",
       "      <td>massless</td>\n",
       "      <td>[0.024190784, 0.006043821, -0.05227672, 0.0457...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.566481</td>\n",
       "      <td>-1.566481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25085</th>\n",
       "      <td>matara</td>\n",
       "      <td>[0.022312755, 0.05083658, -0.019353496, 0.0489...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.572785</td>\n",
       "      <td>-1.572785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25086</th>\n",
       "      <td>suares</td>\n",
       "      <td>[-0.043216027, -0.010845546, -0.026594374, 0.0...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.630726</td>\n",
       "      <td>-1.630726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25087</th>\n",
       "      <td>delusive</td>\n",
       "      <td>[-0.024504628, 0.05090549, 0.07645451, 0.05448...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.562473</td>\n",
       "      <td>-1.562473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25088 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            words                                            vectors  cluster  \\\n",
       "0             the  [-0.04089157, -0.10525032, 0.06359307, 0.03510...        1   \n",
       "1               a  [-0.016692968, -0.13745366, 0.027092986, -0.02...        1   \n",
       "2              to  [-0.009316119, -0.12273791, 0.112017654, 0.009...        1   \n",
       "3             you  [0.01881397, 0.05734981, 0.17161769, 0.0083904...        1   \n",
       "4               i  [-0.0049191266, 0.0117665185, 0.13627413, -0.0...        1   \n",
       "...           ...                                                ...      ...   \n",
       "25083  maliyadeva  [0.025441179, 0.050027493, -0.016706299, 0.047...        0   \n",
       "25084    massless  [0.024190784, 0.006043821, -0.05227672, 0.0457...        0   \n",
       "25085      matara  [0.022312755, 0.05083658, -0.019353496, 0.0489...        0   \n",
       "25086      suares  [-0.043216027, -0.010845546, -0.026594374, 0.0...        0   \n",
       "25087    delusive  [-0.024504628, 0.05090549, 0.07645451, 0.05448...        0   \n",
       "\n",
       "       cluster_value  closeness_score  sentiment_coeff  \n",
       "0                  1         1.030860         1.030860  \n",
       "1                  1         1.046803         1.046803  \n",
       "2                  1         1.070928         1.070928  \n",
       "3                  1         1.090952         1.090952  \n",
       "4                  1         1.099641         1.099641  \n",
       "...              ...              ...              ...  \n",
       "25083             -1         1.584844        -1.584844  \n",
       "25084             -1         1.566481        -1.566481  \n",
       "25085             -1         1.572785        -1.572785  \n",
       "25086             -1         1.630726        -1.630726  \n",
       "25087             -1         1.562473        -1.562473  \n",
       "\n",
       "[25088 rows x 6 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ade6570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = words\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6821f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "690f3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences3=[]\n",
    "for i in sentences2:\n",
    "    sentences3.append(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "807a6195",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"less_toxic\"]=sentences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "939fc259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       this article suck woo woo wooooooo\n",
       "1        and yes people should recognize that but they ...\n",
       "2        western medium yup because every crime in the ...\n",
       "3        and you removed it you numbskull i don_t care ...\n",
       "4        smelly vagina bluerasberry why don_t you be a ...\n",
       "                               ...                        \n",
       "30103    i m_sorry i m not an_admin i will give you thr...\n",
       "30104    i m_sorry i m not an_admin i will give you thr...\n",
       "30105    wow are you out of your mind how wa my edit on...\n",
       "30106    wow are you out of your mind how wa my edit on...\n",
       "30107    wow are you out of your mind how wa my edit on...\n",
       "Name: less_toxic, Length: 30108, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.less_toxic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2ffefdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hector\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x.split(), norm=None)\n",
    "tfidf.fit(df.less_toxic)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(df.less_toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "57d56ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "2c85ad8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'pus'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[0;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8739\u001b[0m         )\n\u001b[1;32m-> 8740\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8742\u001b[0m     def applymap(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    686\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    811\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 812\u001b[1;33m         \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    813\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    814\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                 \u001b[1;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                 \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m                     \u001b[1;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11228/2065552485.py\u001b[0m in \u001b[0;36mreplace_tfidf_words\u001b[1;34m(x, transformed_file, features)\u001b[0m\n\u001b[0;32m     24\u001b[0m     '''\n\u001b[0;32m     25\u001b[0m     \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_tfidf_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{y}'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11228/2065552485.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m     24\u001b[0m     '''\n\u001b[0;32m     25\u001b[0m     \u001b[0mdictionary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_tfidf_dictionary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34mf'{y}'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m: 'pus'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replaced_tfidf_scores = df.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5626bf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [2.0897177568367873, 2.776760753827239, 5.1534...\n",
       "1        [1.6329856895354273, 4.745906979563401, 3.0650...\n",
       "2        [6.363819518988473, 5.823641683209955, 8.47936...\n",
       "3        [1.6329856895354273, 4.619652441241611, 4.6279...\n",
       "4        [8.604529208264431, 14.071826580701172, 9.5208...\n",
       "                               ...                        \n",
       "30103    [4.801846873167803, 6.019274584642149, 4.80184...\n",
       "30104    [4.801846873167803, 6.019274584642149, 4.80184...\n",
       "30105    [5.525682027999934, 2.1785802706471813, 3.0797...\n",
       "30106    [5.525682027999934, 2.1785802706471813, 3.0797...\n",
       "30107    [5.525682027999934, 2.1785802706471813, 3.0797...\n",
       "Length: 30108, dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_tfidf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "16ecb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fc89c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = df.text.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9b2af63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [1.111805915185031, 1.0710539898330051, 1.0307...\n",
       "1        [1.0855379311900761, 1.0326115459561998, 1.061...\n",
       "2        [-1.0169813665612542, 0.9833075433255353, -1.2...\n",
       "3        [1.0855379311900761, 1.0909515282991626, 1.084...\n",
       "4        [-1.0651556483761053, 1.008110958426347, -1.40...\n",
       "                               ...                        \n",
       "30103    [1.099641247462443, 1.0704840662015869, 1.0996...\n",
       "30104    [1.099641247462443, 1.0704840662015869, 1.0996...\n",
       "30105    [1.0379936939510797, 1.0539324818220464, 1.090...\n",
       "30106    [1.0379936939510797, 1.0539324818220464, 1.090...\n",
       "30107    [1.0379936939510797, 1.0539324818220464, 1.090...\n",
       "Name: text, Length: 30108, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_closeness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "411fcd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rate\"]=[1 for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b78e079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, df.less_toxic]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bfc50c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    27899\n",
       "0     2209\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e3a68a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_toxic_score=replacement_df.sentiment_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0a775fcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -50.337755\n",
       "1         135.037336\n",
       "2          21.515241\n",
       "3          99.990358\n",
       "4          -3.069074\n",
       "            ...     \n",
       "30103    1876.926795\n",
       "30104    1876.926795\n",
       "30105     128.727188\n",
       "30106     128.727188\n",
       "30107     128.727188\n",
       "Name: sentiment_rate, Length: 30108, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_toxic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "337d6504",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.more_toxic = df.more_toxic.apply(lambda x: ' '.join(text_cleaning(x)))\n",
    "df.more_toxic = df.more_toxic.apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7b3147b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [word_tokenize(sent) for sent in df.more_toxic]\n",
    "phrases = Phrases(sentences, min_count=30, progress_per=10000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences2 = bigram[sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8f13da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "w2v_model.build_vocab(sentences2, progress_per=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5a122b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14630630, 61012470)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences2, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "244fadf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\AppData\\Local\\Temp/ipykernel_11228/514372312.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "543326ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "65ae72d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = Word2Vec.load(\"word2vec.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "072f64fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e12e9d46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('statem', 0.9179545044898987),\n",
       " ('anonymiss', 0.9165307879447937),\n",
       " ('madchen', 0.9155290722846985),\n",
       " ('huge_faggot', 0.9146426320075989),\n",
       " ('securi', 0.9073453545570374),\n",
       " ('hi_moron', 0.902411162853241),\n",
       " ('nigger_j', 0.8992372155189514),\n",
       " ('facists_so', 0.8987661600112915),\n",
       " ('sex_sexsex', 0.8983744978904724),\n",
       " ('vandalism_rule', 0.8981286883354187)]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "3f35cf9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('culus', 0.9900912642478943),\n",
       " ('coelcan', 0.9803354144096375),\n",
       " ('lifeutosigned', 0.9765209555625916),\n",
       " ('becaouse', 0.976019024848938),\n",
       " ('fcockc', 0.9752219915390015),\n",
       " ('aget', 0.9743158221244812),\n",
       " ('homun', 0.9734430313110352),\n",
       " ('fag_fag', 0.9713580012321472),\n",
       " ('drink_djathinkimacowboy', 0.971011221408844),\n",
       " ('love_juice', 0.9700945615768433)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "793a8729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yourself_go', 0.846086323261261),\n",
       " ('atheist_cunt', 0.819189190864563),\n",
       " ('up_shut', 0.8134414553642273),\n",
       " ('wikipeia', 0.7855981588363647),\n",
       " ('uuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuuu',\n",
       "  0.7218793630599976),\n",
       " ('doit', 0.6687103509902954),\n",
       " ('wekipedia', 0.667383074760437),\n",
       " ('dustin', 0.6628047227859497),\n",
       " ('shinobis', 0.6591443419456482),\n",
       " ('carmegenon', 0.6563659906387329)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"fuck\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d88d91e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_index = 1\n",
    "positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
    "negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "19d3dc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.index_to_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cce408a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d2d23262",
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b9c1a248",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = words\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "bf84c79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences3=[]\n",
    "for i in sentences2:\n",
    "    sentences3.append(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "89d03161",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"more_toxic\"]=sentences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "756ce399",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hector\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x.split(), norm=None)\n",
    "tfidf.fit(df.more_toxic)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(df.more_toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b1b4c1a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = df.text.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8ba8abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, df.more_toxic]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "60e7d1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_toxic_score=replacement_df.sentiment_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed7c646",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "eed32b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, df.less_toxic]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "2c1cd342",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_toxic_score2=replacement_df.sentiment_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "8a8e5744",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=pd.read_csv(\"../../../jigsaw-toxic-severity-rating/validation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5c784163",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(\"worker\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "9f5dbdbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "append=pd.DataFrame(df2.more_toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a85071d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "append.columns=[\"less_toxic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "d5e1e607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.drop(\"more_toxic\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "47134f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff=pd.concat([df2, append])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "44b51398",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.columns=[\"more_toxic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8cbfc61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"index\"]=range(0,len(dff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "6e014525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60211</th>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60212</th>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60213</th>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60214</th>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60215</th>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60216 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              more_toxic\n",
       "index                                                   \n",
       "0                This article sucks \\n\\nwoo woo wooooooo\n",
       "1      \"And yes, people should recognize that but the...\n",
       "2       Western Media?\\n\\nYup, because every crime in...\n",
       "3      And you removed it! You numbskull! I don't car...\n",
       "4       smelly vagina \\n\\nBluerasberry why don't you ...\n",
       "...                                                  ...\n",
       "60211                             get out my large penis\n",
       "60212                             get out my large penis\n",
       "60213                       Piss off you slant eyed-gook\n",
       "60214                       Piss off you slant eyed-gook\n",
       "60215                       Piss off you slant eyed-gook\n",
       "\n",
       "[60216 rows x 1 columns]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dff.set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "9fc028c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.more_toxic = dff.more_toxic.apply(lambda x: ' '.join(text_cleaning(x)))\n",
    "dff.more_toxic = dff.more_toxic.apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "abf6f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [word_tokenize(sent) for sent in dff.more_toxic]\n",
    "phrases = Phrases(sentences, min_count=30, progress_per=10000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences2 = bigram[sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c7b04197",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "w2v_model.build_vocab(sentences2, progress_per=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "7c58c6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31871528, 126090420)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences2, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "9daefaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\AppData\\Local\\Temp/ipykernel_11228/514372312.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8c1724fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "32cd95c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = Word2Vec.load(\"word2vec.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "3db166d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d7cdfd73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('super_gay', 0.9195958971977234),\n",
       " ('persyour', 0.9188180565834045),\n",
       " ('onal', 0.9170994162559509),\n",
       " ('cock_suckersyou', 0.9081459641456604),\n",
       " ('shit_shit', 0.9073291420936584),\n",
       " ('watch_jealouslyfavonian', 0.9073113203048706),\n",
       " ('wierddd', 0.9072612524032593),\n",
       " ('drink_djathinkimacowboy', 0.9069275259971619),\n",
       " ('love_cock', 0.906854510307312),\n",
       " ('vomit_vomit', 0.9065504670143127)]"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d629d9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('shitsack', 0.974092960357666),\n",
       " ('pensis', 0.9728512167930603),\n",
       " ('haaaaaaaaaaaaz', 0.9714035987854004),\n",
       " ('suggestbot', 0.9703049063682556),\n",
       " ('derivation', 0.9683917164802551),\n",
       " ('jewish_ancestryfuck', 0.9642908573150635),\n",
       " ('ancestryfuck_off', 0.9635195136070251),\n",
       " ('chester_marcolfuck', 0.9631128311157227),\n",
       " ('mexican_suck', 0.9628555178642273),\n",
       " ('sherrif', 0.9628304839134216)]"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "08f9ac31",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_index = 1\n",
    "positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
    "negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "2bf140c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.index_to_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "eac4f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "words.columns = ['words']\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "717e69e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "77d3f9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = words\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "a7a8ef9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences3=[]\n",
    "for i in sentences2:\n",
    "    sentences3.append(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "a20083d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"more_toxic\"]=sentences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "8f68d7d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hector\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x.split(), norm=None)\n",
    "tfidf.fit(df.more_toxic)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(df.more_toxic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "39b40938",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.set_index([\"index\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "25da81c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff.columns=[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7fc0eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = dff.text.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "51e476f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[\"closeness_scores\"]=replaced_closeness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "45853e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\Hector\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x.split(), norm=None)\n",
    "tfidf.fit(dff.text)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(dff.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "4d91f4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_tfidf_scores = dff.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "243ffb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, dff.text]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "47474a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "8050339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "10ce1474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "0         47.933236\n",
       "1       -192.095769\n",
       "2        -77.389680\n",
       "3        -83.262213\n",
       "4        -42.769537\n",
       "            ...    \n",
       "60211    -21.002575\n",
       "60212    -21.002575\n",
       "60213      0.322755\n",
       "60214      0.322755\n",
       "60215      0.322755\n",
       "Name: sentiment_rate, Length: 60216, dtype: float64"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df[\"sentiment_rate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "f03723b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_toxic_score=replacement_df.sentiment_rate[0:30108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "e5b0e5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_toxic_score=replacement_df.sentiment_rate[30108:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3bc2d0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "30108    -30.030800\n",
       "30109   -154.168853\n",
       "30110   -606.202330\n",
       "30111    -75.574594\n",
       "30112    -27.320759\n",
       "            ...    \n",
       "60211    -21.002575\n",
       "60212    -21.002575\n",
       "60213      0.322755\n",
       "60214      0.322755\n",
       "60215      0.322755\n",
       "Name: sentiment_rate, Length: 30108, dtype: float64"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "more_toxic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d662fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = pd.read_csv(\"../../../jigsaw-toxic-severity-rating/validation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "7869517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2      \"Atom you don't believe actual photos of mastu...  \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4               hey \\n\\nway to support nazis, you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       Piss off you slant eyed-gook  \n",
       "30106                       Piss off you slant eyed-gook  \n",
       "30107                       Piss off you slant eyed-gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "eef4cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[\"less_toxic_score\"]=replacement_df.sentiment_rate[0:30108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a0b4cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[\"more_toxic_score\"]=mts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "5f157d92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(more_toxic_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d6027d5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(less_toxic_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "bbd71148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index\n",
       "0          47.933236\n",
       "1        -192.095769\n",
       "2         -77.389680\n",
       "3         -83.262213\n",
       "4         -42.769537\n",
       "            ...     \n",
       "30103   -1874.818409\n",
       "30104   -1874.818409\n",
       "30105    -127.437359\n",
       "30106    -127.437359\n",
       "30107    -127.437359\n",
       "Name: sentiment_rate, Length: 30108, dtype: float64"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "less_toxic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "f8dc9c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "mts=mts.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "798b2ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[\"more_toxic_score\"]=mts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "cb4c6613",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>less_toxic_score</th>\n",
       "      <th>more_toxic_score</th>\n",
       "      <th>more_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>47.933236</td>\n",
       "      <td>-30.030800</td>\n",
       "      <td>-30.030800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "      <td>-192.095769</td>\n",
       "      <td>-154.168853</td>\n",
       "      <td>-154.168853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "      <td>-77.389680</td>\n",
       "      <td>-606.202330</td>\n",
       "      <td>-606.202330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "      <td>-83.262213</td>\n",
       "      <td>-75.574594</td>\n",
       "      <td>-75.574594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "      <td>-42.769537</td>\n",
       "      <td>-27.320759</td>\n",
       "      <td>-27.320759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "      <td>-1874.818409</td>\n",
       "      <td>-21.002575</td>\n",
       "      <td>-21.002575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "      <td>-1874.818409</td>\n",
       "      <td>-21.002575</td>\n",
       "      <td>-21.002575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "      <td>-127.437359</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.322755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "      <td>-127.437359</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.322755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "      <td>-127.437359</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.322755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  less_toxic_score  \\\n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...         47.933236   \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...       -192.095769   \n",
       "2      \"Atom you don't believe actual photos of mastu...        -77.389680   \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...        -83.262213   \n",
       "4               hey \\n\\nway to support nazis, you racist        -42.769537   \n",
       "...                                                  ...               ...   \n",
       "30103                             get out my large penis      -1874.818409   \n",
       "30104                             get out my large penis      -1874.818409   \n",
       "30105                       Piss off you slant eyed-gook       -127.437359   \n",
       "30106                       Piss off you slant eyed-gook       -127.437359   \n",
       "30107                       Piss off you slant eyed-gook       -127.437359   \n",
       "\n",
       "       more_toxic_score  more_score  \n",
       "0            -30.030800  -30.030800  \n",
       "1           -154.168853 -154.168853  \n",
       "2           -606.202330 -606.202330  \n",
       "3            -75.574594  -75.574594  \n",
       "4            -27.320759  -27.320759  \n",
       "...                 ...         ...  \n",
       "30103        -21.002575  -21.002575  \n",
       "30104        -21.002575  -21.002575  \n",
       "30105          0.322755    0.322755  \n",
       "30106          0.322755    0.322755  \n",
       "30107          0.322755    0.322755  \n",
       "\n",
       "[30108 rows x 6 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "65049915",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores=[]\n",
    "for index, row in vd.iterrows():\n",
    "    if row[\"less_toxic_score\"]>=row[\"more_toxic_score\"]:\n",
    "        scores.append(1)\n",
    "    else:\n",
    "        scores.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "dc4d352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[\"scores\"]=scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "171b5626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>less_toxic_score</th>\n",
       "      <th>more_toxic_score</th>\n",
       "      <th>more_score</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "      <td>47.933236</td>\n",
       "      <td>-30.030800</td>\n",
       "      <td>-30.030800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "      <td>-192.095769</td>\n",
       "      <td>-154.168853</td>\n",
       "      <td>-154.168853</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "      <td>-77.389680</td>\n",
       "      <td>-606.202330</td>\n",
       "      <td>-606.202330</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "      <td>-83.262213</td>\n",
       "      <td>-75.574594</td>\n",
       "      <td>-75.574594</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "      <td>-42.769537</td>\n",
       "      <td>-27.320759</td>\n",
       "      <td>-27.320759</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "      <td>-1874.818409</td>\n",
       "      <td>-21.002575</td>\n",
       "      <td>-21.002575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "      <td>-1874.818409</td>\n",
       "      <td>-21.002575</td>\n",
       "      <td>-21.002575</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "      <td>-127.437359</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "      <td>-127.437359</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "      <td>-127.437359</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0.322755</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  less_toxic_score  \\\n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...         47.933236   \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...       -192.095769   \n",
       "2      \"Atom you don't believe actual photos of mastu...        -77.389680   \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...        -83.262213   \n",
       "4               hey \\n\\nway to support nazis, you racist        -42.769537   \n",
       "...                                                  ...               ...   \n",
       "30103                             get out my large penis      -1874.818409   \n",
       "30104                             get out my large penis      -1874.818409   \n",
       "30105                       Piss off you slant eyed-gook       -127.437359   \n",
       "30106                       Piss off you slant eyed-gook       -127.437359   \n",
       "30107                       Piss off you slant eyed-gook       -127.437359   \n",
       "\n",
       "       more_toxic_score  more_score  scores  \n",
       "0            -30.030800  -30.030800       1  \n",
       "1           -154.168853 -154.168853       0  \n",
       "2           -606.202330 -606.202330       1  \n",
       "3            -75.574594  -75.574594       0  \n",
       "4            -27.320759  -27.320759       0  \n",
       "...                 ...         ...     ...  \n",
       "30103        -21.002575  -21.002575       0  \n",
       "30104        -21.002575  -21.002575       0  \n",
       "30105          0.322755    0.322755       0  \n",
       "30106          0.322755    0.322755       0  \n",
       "30107          0.322755    0.322755       0  \n",
       "\n",
       "[30108 rows x 7 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "97807a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5464\n",
       "1    0.4536\n",
       "Name: scores, dtype: float64"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd[\"scores\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e8413f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = vd[vd.less_toxic_score != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "4de94479",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = vd[vd.more_toxic_score != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "2d92af1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.936252\n",
       "0    0.063748\n",
       "Name: scores, dtype: float64"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd[\"scores\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fecaed4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30103"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8cb11fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
