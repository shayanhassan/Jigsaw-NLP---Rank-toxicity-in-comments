{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d653bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from re import sub\n",
    "import multiprocessing\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import get_tmpfile\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "\n",
    "from time import time \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7447d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"../../../jigsaw-toxic-severity-rating/comments_to_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3f4a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>\"\\n \\n\\nGjalexei, you asked about whether ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>Looks like be have an abuser , can you please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>I confess to having complete (and apparently b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>\"\\n\\nFreud's ideas are certainly much discusse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>It is not just you. This is a laundry list of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>504235362</td>\n",
       "      <td>Go away, you annoying vandal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>504235566</td>\n",
       "      <td>This user is a vandal.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>504308177</td>\n",
       "      <td>\" \\n\\nSorry to sound like a pain, but one by f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>504570375</td>\n",
       "      <td>Well it's pretty fucking irrelevant now I'm un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>504598250</td>\n",
       "      <td>The team name is Great Britain and Northern Ir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7537 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id                                               text\n",
       "0         114890  \"\\n \\n\\nGjalexei, you asked about whether ther...\n",
       "1         732895  Looks like be have an abuser , can you please ...\n",
       "2        1139051  I confess to having complete (and apparently b...\n",
       "3        1434512  \"\\n\\nFreud's ideas are certainly much discusse...\n",
       "4        2084821  It is not just you. This is a laundry list of ...\n",
       "...          ...                                                ...\n",
       "7532   504235362                      Go away, you annoying vandal.\n",
       "7533   504235566                           This user is a vandal.  \n",
       "7534   504308177  \" \\n\\nSorry to sound like a pain, but one by f...\n",
       "7535   504570375  Well it's pretty fucking irrelevant now I'm un...\n",
       "7536   504598250  The team name is Great Britain and Northern Ir...\n",
       "\n",
       "[7537 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b98c40c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "def text_cleaning(text):\n",
    "    if text:\n",
    "        text = ' '.join(text.split('.'))\n",
    "        text = re.sub('\\/',' ',text)\n",
    "        text = re.sub(r'\\\\',' ',text)\n",
    "        text = re.sub(r'((http)\\S+)','',text)\n",
    "        text = re.sub(r'\\s+', ' ', re.sub('[^A-Za-z]', ' ', text.strip().lower())).strip()\n",
    "        text = re.sub(r'\\W+', ' ', text.strip().lower()).strip()\n",
    "        text = [word for word in text.split()]\n",
    "        return text\n",
    "    return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "822c9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "435bd62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizing(s):\n",
    "    l=s.split(\" \")\n",
    "    l2=[lemmatizer.lemmatize(word) for word in l]\n",
    "    s=\" \".join(l2)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91825f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(lambda x: ' '.join(text_cleaning(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c960045",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.text = df.text.apply(lambda x: lemmatizing(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc019326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>gjalexei you asked about whether there is an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>look like be have an abuser can you please loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>i confess to having complete and apparently bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>freud s idea are certainly much discussed toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>it is not just you this is a laundry list of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>504235362</td>\n",
       "      <td>go away you annoying vandal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>504235566</td>\n",
       "      <td>this user is a vandal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>504308177</td>\n",
       "      <td>sorry to sound like a pain but one by followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>504570375</td>\n",
       "      <td>well it s pretty fucking irrelevant now i m un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>504598250</td>\n",
       "      <td>the team name is great britain and northern ir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7537 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id                                               text\n",
       "0         114890  gjalexei you asked about whether there is an a...\n",
       "1         732895  look like be have an abuser can you please loo...\n",
       "2        1139051  i confess to having complete and apparently bl...\n",
       "3        1434512  freud s idea are certainly much discussed toda...\n",
       "4        2084821  it is not just you this is a laundry list of s...\n",
       "...          ...                                                ...\n",
       "7532   504235362                        go away you annoying vandal\n",
       "7533   504235566                              this user is a vandal\n",
       "7534   504308177  sorry to sound like a pain but one by followin...\n",
       "7535   504570375  well it s pretty fucking irrelevant now i m un...\n",
       "7536   504598250  the team name is great britain and northern ir...\n",
       "\n",
       "[7537 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a69b15a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'look like be have an abuser can you please look into this thanks'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = [row for row in df.text]\n",
    "phrases = Phrases(sent, min_count=1, progress_per=50000)\n",
    "bigram = Phraser(phrases)\n",
    "sentences = bigram[sent]\n",
    "sentences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd3a56ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [word_tokenize(sent) for sent in df.text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80ad370",
   "metadata": {},
   "outputs": [],
   "source": [
    "allwords=[]\n",
    "for sentence in sentences:\n",
    "    for word in sentence:\n",
    "        allwords.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24380602",
   "metadata": {},
   "outputs": [],
   "source": [
    "phrases = Phrases(sentences, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84de6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f47ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2 = bigram[sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea89bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=3,\n",
    "                     window=4,\n",
    "                     vector_size=300,\n",
    "                     sample=1e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=multiprocessing.cpu_count()-1)\n",
    "\n",
    "start = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4dd1c1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3295224, 16589040)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f65af536",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\AppData\\Local\\Temp/ipykernel_8624/514372312.py:1: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  w2v_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "source": [
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85d54e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('reply', 0.9687471985816956),\n",
       " ('feel', 0.9684051871299744),\n",
       " ('warned', 0.9671880006790161),\n",
       " ('account', 0.9670696258544922),\n",
       " ('resolve', 0.9670256972312927),\n",
       " ('welcome', 0.9663922786712646),\n",
       " ('insult', 0.9645615220069885),\n",
       " ('respond', 0.9631102085113525),\n",
       " ('blanking', 0.9630785584449768),\n",
       " ('asking', 0.9627591371536255)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"help\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d24a1f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('up', 0.9738149642944336),\n",
       " ('albino', 0.9042350053787231),\n",
       " ('fuck', 0.903282105922699),\n",
       " ('niggertard', 0.9000552296638489),\n",
       " ('inch', 0.899649441242218),\n",
       " ('molesting', 0.8990961909294128),\n",
       " ('rw', 0.8983824849128723),\n",
       " ('gwernol', 0.8979898691177368),\n",
       " ('dvd', 0.8838503360748291),\n",
       " ('geek', 0.8692071437835693)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"shut\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb2ea8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model.save(\"word2vec.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40cc4dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "438252a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = Word2Vec.load(\"word2vec.model\").wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c275c3e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x285042fdbe0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c8d575ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, max_iter=1000, random_state=True, n_init=50).fit(X=word_vectors.vectors.astype('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "488d4952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('aswell', 0.9994921684265137),\n",
       " ('everyones', 0.9994344711303711),\n",
       " ('somone', 0.9993751645088196),\n",
       " ('relating', 0.9993699193000793),\n",
       " ('compelled', 0.9993450045585632),\n",
       " ('smarter', 0.9993321299552917),\n",
       " ('dipshit', 0.9992955327033997),\n",
       " ('egordon', 0.9992589354515076),\n",
       " ('ruined', 0.999235987663269),\n",
       " ('ilovedirtbikes', 0.9992008209228516)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[0], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "173eec88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('estate', 0.9997875094413757),\n",
       " ('menacing', 0.9997500777244568),\n",
       " ('portrayed', 0.9997465014457703),\n",
       " ('askolnick', 0.9997384548187256),\n",
       " ('glen', 0.9997234344482422),\n",
       " ('byte', 0.9997187852859497),\n",
       " ('san', 0.999714732170105),\n",
       " ('commission', 0.9997142553329468),\n",
       " ('mandate', 0.9997122883796692),\n",
       " ('taliban', 0.9997117519378662)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_vector(model.cluster_centers_[1], topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f6abe071",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_cluster_index = 1\n",
    "positive_cluster_center = model.cluster_centers_[positive_cluster_index]\n",
    "negative_cluster_center = model.cluster_centers_[1-positive_cluster_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3374a201",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.DataFrame(word_vectors.index_to_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a3b1ecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9133</th>\n",
       "      <td>portrait</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9134</th>\n",
       "      <td>taliban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9135</th>\n",
       "      <td>reptile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9136</th>\n",
       "      <td>enacted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9137</th>\n",
       "      <td>diem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9138 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0     wikipedia\n",
       "1       article\n",
       "2          page\n",
       "3          fuck\n",
       "4          like\n",
       "...         ...\n",
       "9133   portrait\n",
       "9134    taliban\n",
       "9135    reptile\n",
       "9136    enacted\n",
       "9137       diem\n",
       "\n",
       "[9138 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f868810c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(w2v_model.wv.most_similar(positive=[\"retard\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ee8b35d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('inbred', 0.9703599214553833),\n",
       " ('twat', 0.9685810804367065),\n",
       " ('punk', 0.9682215452194214),\n",
       " ('wit', 0.9661067724227905),\n",
       " ('ain', 0.9660205841064453),\n",
       " ('queer', 0.9658352136611938),\n",
       " ('bro', 0.9654372930526733),\n",
       " ('bite', 0.9646785855293274),\n",
       " ('lame', 0.9645381569862366),\n",
       " ('mommy', 0.9640811085700989)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"retard\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a26a5826",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordtox={}\n",
    "for i in w2v_model.wv.most_similar(positive=[\"retard\"]):\n",
    "    wordtox[i[0]]=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0de60ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordpos={}\n",
    "for i in w2v_model.wv.most_similar(positive=[\"thanks\"]):\n",
    "    wordpos[i[0]]=i[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d13f6816",
   "metadata": {},
   "outputs": [],
   "source": [
    "words.columns = ['words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f44c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_df=pd.DataFrame(wordtox.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1b465b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_df.columns=[\"words\", \"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a70b633f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df=pd.DataFrame(wordpos.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e376d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df.columns=[\"words\", \"values\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3fad1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8078eeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_score=[]\n",
    "for i in words[\"words\"]:\n",
    "    toxic_score.append(tox_df.loc[tox_df[\"words\"] == i, 'values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6ee233ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_score=[]\n",
    "for i in words[\"words\"]:\n",
    "    pos_score.append(pos_df.loc[pos_df[\"words\"] == i, 'values'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "952f9299",
   "metadata": {},
   "outputs": [],
   "source": [
    "words[\"tox\"]=toxic_score\n",
    "words[\"pos\"]=pos_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4cd64f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "words['vectors'] = words.words.apply(lambda x: word_vectors[f'{x}'])\n",
    "words['cluster'] = words.vectors.apply(lambda x: model.predict([np.array(x)]))\n",
    "words.cluster = words.cluster.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a32157e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "words['cluster_value'] = [1 if i==positive_cluster_index else -1 for i in words.cluster]\n",
    "words['closeness_score'] = words.apply(lambda x: 1/(model.transform([x.vectors]).min()), axis=1)\n",
    "words['sentiment_coeff'] = words.closeness_score * words.cluster_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6725d08c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>vectors</th>\n",
       "      <th>cluster</th>\n",
       "      <th>cluster_value</th>\n",
       "      <th>closeness_score</th>\n",
       "      <th>sentiment_coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>[0.06806515, 0.07502727, 0.045670383, -0.06687...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.595016</td>\n",
       "      <td>1.595016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>you</td>\n",
       "      <td>[0.08015253, -0.026329357, 0.012827262, -0.083...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.130235</td>\n",
       "      <td>-1.130235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>[0.0981175, 0.065807104, 0.07202283, -0.060753...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.778274</td>\n",
       "      <td>-1.778274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>to</td>\n",
       "      <td>[0.05603963, 0.01304679, -0.016778206, -0.1138...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.696556</td>\n",
       "      <td>-1.696556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i</td>\n",
       "      <td>[0.08837415, -0.008363632, 0.0071330224, -0.06...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1.144578</td>\n",
       "      <td>-1.144578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9263</th>\n",
       "      <td>indicative</td>\n",
       "      <td>[0.08683934, 0.061126996, 0.05128193, -0.10123...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.613662</td>\n",
       "      <td>21.613662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9264</th>\n",
       "      <td>shadow</td>\n",
       "      <td>[0.08866689, 0.055029392, 0.050759654, -0.1061...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11.281194</td>\n",
       "      <td>-11.281194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9265</th>\n",
       "      <td>funk</td>\n",
       "      <td>[0.09127148, 0.054746192, 0.05313637, -0.10553...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>15.806943</td>\n",
       "      <td>-15.806943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9266</th>\n",
       "      <td>madness</td>\n",
       "      <td>[0.08765054, 0.061534185, 0.0514894, -0.103769...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15.600050</td>\n",
       "      <td>15.600050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9267</th>\n",
       "      <td>diem</td>\n",
       "      <td>[0.083085366, 0.062109634, 0.04984106, -0.1028...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.928284</td>\n",
       "      <td>19.928284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9268 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           words                                            vectors  cluster  \\\n",
       "0            the  [0.06806515, 0.07502727, 0.045670383, -0.06687...        1   \n",
       "1            you  [0.08015253, -0.026329357, 0.012827262, -0.083...        0   \n",
       "2              a  [0.0981175, 0.065807104, 0.07202283, -0.060753...        0   \n",
       "3             to  [0.05603963, 0.01304679, -0.016778206, -0.1138...        0   \n",
       "4              i  [0.08837415, -0.008363632, 0.0071330224, -0.06...        0   \n",
       "...          ...                                                ...      ...   \n",
       "9263  indicative  [0.08683934, 0.061126996, 0.05128193, -0.10123...        1   \n",
       "9264      shadow  [0.08866689, 0.055029392, 0.050759654, -0.1061...        0   \n",
       "9265        funk  [0.09127148, 0.054746192, 0.05313637, -0.10553...        0   \n",
       "9266     madness  [0.08765054, 0.061534185, 0.0514894, -0.103769...        1   \n",
       "9267        diem  [0.083085366, 0.062109634, 0.04984106, -0.1028...        1   \n",
       "\n",
       "      cluster_value  closeness_score  sentiment_coeff  \n",
       "0                 1         1.595016         1.595016  \n",
       "1                -1         1.130235        -1.130235  \n",
       "2                -1         1.778274        -1.778274  \n",
       "3                -1         1.696556        -1.696556  \n",
       "4                -1         1.144578        -1.144578  \n",
       "...             ...              ...              ...  \n",
       "9263              1        21.613662        21.613662  \n",
       "9264             -1        11.281194       -11.281194  \n",
       "9265             -1        15.806943       -15.806943  \n",
       "9266              1        15.600050        15.600050  \n",
       "9267              1        19.928284        19.928284  \n",
       "\n",
       "[9268 rows x 6 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ade6570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_map = words\n",
    "sentiment_dict = dict(zip(sentiment_map.words.values, sentiment_map.sentiment_coeff.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6821f752",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "24a4bc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       gjalexei you asked about whether there is an a...\n",
       "1       look like be have an abuser can you please loo...\n",
       "2       i confess to having complete and apparently bl...\n",
       "3       freud s idea are certainly much discussed toda...\n",
       "4       it is not just you this is a laundry list of s...\n",
       "                              ...                        \n",
       "7532                          go away you annoying vandal\n",
       "7533                                this user is a vandal\n",
       "7534    sorry to sound like a pain but one by followin...\n",
       "7535    well it s pretty fucking irrelevant now i m un...\n",
       "7536    the team name is great britain and northern ir...\n",
       "Name: text, Length: 7537, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b75b0ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences3=[]\n",
    "for i in sentences2:\n",
    "    sentences3.append(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1b8b6224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=sentences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a22472d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       gjalexei you asked about whether there is an a...\n",
       "1       look_like be have an abuser can you please loo...\n",
       "2       i confess to having complete and apparently bl...\n",
       "3       freud s idea are certainly much discussed toda...\n",
       "4       it is not just you this is a laundry list of s...\n",
       "                              ...                        \n",
       "7532                          go_away you annoying vandal\n",
       "7533                                this user is a vandal\n",
       "7534    sorry to sound like a pain but one by followin...\n",
       "7535    well it s pretty fucking irrelevant now i_m un...\n",
       "7536    the team name is great britain and northern ir...\n",
       "Name: text, Length: 7537, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "2ffefdc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hector\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(tokenizer=lambda x: x.split(), norm=None)\n",
    "tfidf.fit(df.text)\n",
    "features = pd.Series(tfidf.get_feature_names())\n",
    "transformed = tfidf.transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57d56ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tfidf_dictionary(x, transformed_file, features):\n",
    "    '''\n",
    "    create dictionary for each input sentence x, where each word has assigned its tfidf score\n",
    "    \n",
    "    inspired  by function from this wonderful article: \n",
    "    https://medium.com/analytics-vidhya/automated-keyword-extraction-from-articles-using-nlp-bfd864f41b34\n",
    "    \n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "\n",
    "    '''\n",
    "    vector_coo = transformed_file[x.name].tocoo()\n",
    "    vector_coo.col = features.iloc[vector_coo.col].values\n",
    "    dict_from_coo = dict(zip(vector_coo.col, vector_coo.data))\n",
    "    return dict_from_coo\n",
    "\n",
    "def replace_tfidf_words(x, transformed_file, features):\n",
    "    '''\n",
    "    replacing each word with it's calculated tfidf dictionary with scores of each word\n",
    "    x - row of dataframe, containing sentences, and their indexes,\n",
    "    transformed_file - all sentences transformed with TfidfVectorizer\n",
    "    features - names of all words in corpus used in TfidfVectorizer\n",
    "    '''\n",
    "    dictionary = create_tfidf_dictionary(x, transformed_file, features)   \n",
    "    return list(map(lambda y:dictionary[f'{y}'], x.text.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2c85ad8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.72 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "replaced_tfidf_scores = df.apply(lambda x: replace_tfidf_words(x, transformed, features), axis=1)#this step takes around 3-4 minutes minutes to calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5626bf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [9.234564993267135, 9.189343864727395, 5.42790...\n",
       "1       [5.596978833540749, 2.6622824505731275, 2.4053...\n",
       "2       [6.868176570656416, 8.318274261392979, 3.30009...\n",
       "3       [65.0876216367922, 16.773118546938544, 9.86099...\n",
       "4       [3.8050457038724925, 3.6178183536940915, 2.197...\n",
       "                              ...                        \n",
       "7532    [6.40135164921092, 1.5315573107878993, 6.21414...\n",
       "7533    [2.180115335134195, 3.509347237890869, 1.80890...\n",
       "7534    [4.654712615263334, 3.3000920259511544, 5.5209...\n",
       "7535    [3.6586158901208194, 3.8050457038724925, 2.396...\n",
       "7536    [1.5709225039038672, 6.077564572117022, 4.1346...\n",
       "Length: 7537, dtype: object"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_tfidf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16ecb978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_sentiment_words(word, sentiment_dict):\n",
    "    '''\n",
    "    replacing each word with its associated sentiment score from sentiment dict\n",
    "    '''\n",
    "    try:\n",
    "        out = sentiment_dict[word]\n",
    "    except KeyError:\n",
    "        out = 0\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fc89c911",
   "metadata": {},
   "outputs": [],
   "source": [
    "replaced_closeness_scores = df.text.apply(lambda x: list(map(lambda y: replace_sentiment_words(y, sentiment_dict), x.split())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9b2af63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [0, -1.1302348039775392, -8.0958983888947, -3....\n",
       "1       [0, -4.958652977928704, -3.7053719759862966, 4...\n",
       "2       [-1.1445781613963544, -10.01470727091792, -1.6...\n",
       "3       [4.4474094760884455, 3.275557415500769, -8.948...\n",
       "4       [-1.8895594747263174, 1.4702613127852697, -1.9...\n",
       "                              ...                        \n",
       "7532    [0, -1.1302348039775392, -8.013320632487133, -...\n",
       "7533    [-1.9141796151404546, -1.4872076875304403, 1.4...\n",
       "7534    [-3.0670387718934706, -1.6965557751890572, -9....\n",
       "7535    [-5.8805887997114645, -1.8895594747263174, 3.2...\n",
       "7536    [1.5950155842943887, 6.193798580597679, -1.935...\n",
       "Name: text, Length: 7537, dtype: object"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replaced_closeness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9aeafd44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114890</td>\n",
       "      <td>gjalexei you asked about whether there is an a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>732895</td>\n",
       "      <td>look_like be have an abuser can you please loo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1139051</td>\n",
       "      <td>i confess to having complete and apparently bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1434512</td>\n",
       "      <td>freud s idea are certainly much discussed toda...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2084821</td>\n",
       "      <td>it is not just you this is a laundry list of s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>504235362</td>\n",
       "      <td>go_away you annoying vandal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>504235566</td>\n",
       "      <td>this user is a vandal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>504308177</td>\n",
       "      <td>sorry to sound like a pain but one by followin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>504570375</td>\n",
       "      <td>well it s pretty fucking irrelevant now i_m un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>504598250</td>\n",
       "      <td>the team name is great britain and northern ir...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7537 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      comment_id                                               text\n",
       "0         114890  gjalexei you asked about whether there is an a...\n",
       "1         732895  look_like be have an abuser can you please loo...\n",
       "2        1139051  i confess to having complete and apparently bl...\n",
       "3        1434512  freud s idea are certainly much discussed toda...\n",
       "4        2084821  it is not just you this is a laundry list of s...\n",
       "...          ...                                                ...\n",
       "7532   504235362                        go_away you annoying vandal\n",
       "7533   504235566                              this user is a vandal\n",
       "7534   504308177  sorry to sound like a pain but one by followin...\n",
       "7535   504570375  well it s pretty fucking irrelevant now i_m un...\n",
       "7536   504598250  the team name is great britain and northern ir...\n",
       "\n",
       "[7537 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "411fcd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"rate\"]=[1 for i in range(len(df))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b78e079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_df = pd.DataFrame(data=[replaced_closeness_scores, replaced_tfidf_scores, df.text, df.rate]).T\n",
    "replacement_df.columns = ['sentiment_coeff', 'tfidf_scores', 'sentence', 'sentiment']\n",
    "replacement_df['sentiment_rate'] = replacement_df.apply(lambda x: np.array(x.loc['sentiment_coeff']) @ np.array(x.loc['tfidf_scores']), axis=1)\n",
    "replacement_df['prediction'] = (replacement_df.sentiment_rate>0).astype('int8')\n",
    "replacement_df['sentiment'] = [1 if i==1 else 0 for i in replacement_df.sentiment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "306f4712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    7537\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bfc50c95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4130\n",
       "1    3407\n",
       "Name: prediction, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df.prediction.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e3a68a0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_coeff</th>\n",
       "      <th>tfidf_scores</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_rate</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, -1.1302348039775392, -8.0958983888947, -3....</td>\n",
       "      <td>[9.234564993267135, 9.189343864727395, 5.42790...</td>\n",
       "      <td>gjalexei you asked about whether there is an a...</td>\n",
       "      <td>1</td>\n",
       "      <td>261.932183</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, -4.958652977928704, -3.7053719759862966, 4...</td>\n",
       "      <td>[5.596978833540749, 2.6622824505731275, 2.4053...</td>\n",
       "      <td>look_like be have an abuser can you please loo...</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.533344</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-1.1445781613963544, -10.01470727091792, -1.6...</td>\n",
       "      <td>[6.868176570656416, 8.318274261392979, 3.30009...</td>\n",
       "      <td>i confess to having complete and apparently bl...</td>\n",
       "      <td>1</td>\n",
       "      <td>886.624535</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[4.4474094760884455, 3.275557415500769, -8.948...</td>\n",
       "      <td>[65.0876216367922, 16.773118546938544, 9.86099...</td>\n",
       "      <td>freud s idea are certainly much discussed toda...</td>\n",
       "      <td>1</td>\n",
       "      <td>8468.453356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-1.8895594747263174, 1.4702613127852697, -1.9...</td>\n",
       "      <td>[3.8050457038724925, 3.6178183536940915, 2.197...</td>\n",
       "      <td>it is not just you this is a laundry list of s...</td>\n",
       "      <td>1</td>\n",
       "      <td>281.881128</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>[0, -1.1302348039775392, -8.013320632487133, -...</td>\n",
       "      <td>[6.40135164921092, 1.5315573107878993, 6.21414...</td>\n",
       "      <td>go_away you annoying vandal</td>\n",
       "      <td>1</td>\n",
       "      <td>-90.111189</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7533</th>\n",
       "      <td>[-1.9141796151404546, -1.4872076875304403, 1.4...</td>\n",
       "      <td>[2.180115335134195, 3.509347237890869, 1.80890...</td>\n",
       "      <td>this user is a vandal</td>\n",
       "      <td>1</td>\n",
       "      <td>-48.005908</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7534</th>\n",
       "      <td>[-3.0670387718934706, -1.6965557751890572, -9....</td>\n",
       "      <td>[4.654712615263334, 3.3000920259511544, 5.5209...</td>\n",
       "      <td>sorry to sound like a pain but one by followin...</td>\n",
       "      <td>1</td>\n",
       "      <td>-707.513645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>[-5.8805887997114645, -1.8895594747263174, 3.2...</td>\n",
       "      <td>[3.6586158901208194, 3.8050457038724925, 2.396...</td>\n",
       "      <td>well it s pretty fucking irrelevant now i_m un...</td>\n",
       "      <td>1</td>\n",
       "      <td>-228.010998</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7536</th>\n",
       "      <td>[1.5950155842943887, 6.193798580597679, -1.935...</td>\n",
       "      <td>[1.5709225039038672, 6.077564572117022, 4.1346...</td>\n",
       "      <td>the team name is great britain and northern ir...</td>\n",
       "      <td>1</td>\n",
       "      <td>18.095327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7537 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sentiment_coeff  \\\n",
       "0     [0, -1.1302348039775392, -8.0958983888947, -3....   \n",
       "1     [0, -4.958652977928704, -3.7053719759862966, 4...   \n",
       "2     [-1.1445781613963544, -10.01470727091792, -1.6...   \n",
       "3     [4.4474094760884455, 3.275557415500769, -8.948...   \n",
       "4     [-1.8895594747263174, 1.4702613127852697, -1.9...   \n",
       "...                                                 ...   \n",
       "7532  [0, -1.1302348039775392, -8.013320632487133, -...   \n",
       "7533  [-1.9141796151404546, -1.4872076875304403, 1.4...   \n",
       "7534  [-3.0670387718934706, -1.6965557751890572, -9....   \n",
       "7535  [-5.8805887997114645, -1.8895594747263174, 3.2...   \n",
       "7536  [1.5950155842943887, 6.193798580597679, -1.935...   \n",
       "\n",
       "                                           tfidf_scores  \\\n",
       "0     [9.234564993267135, 9.189343864727395, 5.42790...   \n",
       "1     [5.596978833540749, 2.6622824505731275, 2.4053...   \n",
       "2     [6.868176570656416, 8.318274261392979, 3.30009...   \n",
       "3     [65.0876216367922, 16.773118546938544, 9.86099...   \n",
       "4     [3.8050457038724925, 3.6178183536940915, 2.197...   \n",
       "...                                                 ...   \n",
       "7532  [6.40135164921092, 1.5315573107878993, 6.21414...   \n",
       "7533  [2.180115335134195, 3.509347237890869, 1.80890...   \n",
       "7534  [4.654712615263334, 3.3000920259511544, 5.5209...   \n",
       "7535  [3.6586158901208194, 3.8050457038724925, 2.396...   \n",
       "7536  [1.5709225039038672, 6.077564572117022, 4.1346...   \n",
       "\n",
       "                                               sentence  sentiment  \\\n",
       "0     gjalexei you asked about whether there is an a...          1   \n",
       "1     look_like be have an abuser can you please loo...          1   \n",
       "2     i confess to having complete and apparently bl...          1   \n",
       "3     freud s idea are certainly much discussed toda...          1   \n",
       "4     it is not just you this is a laundry list of s...          1   \n",
       "...                                                 ...        ...   \n",
       "7532                        go_away you annoying vandal          1   \n",
       "7533                              this user is a vandal          1   \n",
       "7534  sorry to sound like a pain but one by followin...          1   \n",
       "7535  well it s pretty fucking irrelevant now i_m un...          1   \n",
       "7536  the team name is great britain and northern ir...          1   \n",
       "\n",
       "      sentiment_rate  prediction  \n",
       "0         261.932183           1  \n",
       "1         -37.533344           0  \n",
       "2         886.624535           1  \n",
       "3        8468.453356           1  \n",
       "4         281.881128           1  \n",
       "...              ...         ...  \n",
       "7532      -90.111189           0  \n",
       "7533      -48.005908           0  \n",
       "7534     -707.513645           0  \n",
       "7535     -228.010998           0  \n",
       "7536       18.095327           1  \n",
       "\n",
       "[7537 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d662fecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = pd.read_csv(\"../../../jigsaw-toxic-severity-rating/validation_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "7869517c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>This article sucks \\n\\nwoo woo wooooooo</td>\n",
       "      <td>WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>\"And yes, people should recognize that but the...</td>\n",
       "      <td>Daphne Guinness \\n\\nTop of the mornin' my fav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>Western Media?\\n\\nYup, because every crime in...</td>\n",
       "      <td>\"Atom you don't believe actual photos of mastu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>And you removed it! You numbskull! I don't car...</td>\n",
       "      <td>You seem to have sand in your vagina.\\n\\nMight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina \\n\\nBluerasberry why don't you ...</td>\n",
       "      <td>hey \\n\\nway to support nazis, you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>I'm sorry. I'm not an admin. I will give you t...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow...\\nare you out of your mind, how was my e...</td>\n",
       "      <td>Piss off you slant eyed-gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313            This article sucks \\n\\nwoo woo wooooooo   \n",
       "1         188  \"And yes, people should recognize that but the...   \n",
       "2          82   Western Media?\\n\\nYup, because every crime in...   \n",
       "3         347  And you removed it! You numbskull! I don't car...   \n",
       "4         539   smelly vagina \\n\\nBluerasberry why don't you ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30104     527  I'm sorry. I'm not an admin. I will give you t...   \n",
       "30105     352  wow...\\nare you out of your mind, how was my e...   \n",
       "30106     311  wow...\\nare you out of your mind, how was my e...   \n",
       "30107      54  wow...\\nare you out of your mind, how was my e...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      WHAT!!!!!!!!?!?!!?!?!!?!?!?!?!!!!!!!!!!!!!!!!!...  \n",
       "1       Daphne Guinness \\n\\nTop of the mornin' my fav...  \n",
       "2      \"Atom you don't believe actual photos of mastu...  \n",
       "3      You seem to have sand in your vagina.\\n\\nMight...  \n",
       "4               hey \\n\\nway to support nazis, you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       Piss off you slant eyed-gook  \n",
       "30106                       Piss off you slant eyed-gook  \n",
       "30107                       Piss off you slant eyed-gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "cadd01cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd.less_toxic = vd.less_toxic.apply(lambda x: ' '.join(text_cleaning(x)))\n",
    "vd.more_toxic = vd.more_toxic.apply(lambda x: ' '.join(text_cleaning(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fea60e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd.less_toxic = vd.less_toxic.apply(lambda x: lemmatizing(x))\n",
    "vd.more_toxic = vd.more_toxic.apply(lambda x: lemmatizing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "c5d2c20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_sentences = [word_tokenize(sent) for sent in vd.less_toxic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3b24cc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_sentences = [word_tokenize(sent) for sent in vd.more_toxic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7c0b1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_sentences2 = bigram[lt_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "fc9576f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_sentences2 = bigram[mt_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "25758dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lt_sentences3=[]\n",
    "for i in lt_sentences2:\n",
    "    lt_sentences3.append(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7d124bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_sentences3=[]\n",
    "for i in mt_sentences2:\n",
    "    mt_sentences3.append(\" \".join(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8b12e28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[\"less_toxic\"]=lt_sentences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a1d1aff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[\"more_toxic\"]=mt_sentences3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "742dd5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>this article suck woo woo wooooooo</td>\n",
       "      <td>what wher is your sexy pic gone from your main...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>and yes people should recognize that but they ...</td>\n",
       "      <td>daphne guinness top of the mornin my favourite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>western medium yup because every crime in the ...</td>\n",
       "      <td>atom you don t believe actual photo of masturb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>and you removed it you numbskull i don t care ...</td>\n",
       "      <td>you seem to have sand in your vagina might wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina bluerasberry why don t you be a ...</td>\n",
       "      <td>hey way to support nazi you racist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>i m sorry i m not an admin i will give you thr...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>i m sorry i m not an admin i will give you thr...</td>\n",
       "      <td>get out my large penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow are you out of your mind how wa my edit on...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow are you out of your mind how wa my edit on...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow are you out of your mind how wa my edit on...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313                 this article suck woo woo wooooooo   \n",
       "1         188  and yes people should recognize that but they ...   \n",
       "2          82  western medium yup because every crime in the ...   \n",
       "3         347  and you removed it you numbskull i don t care ...   \n",
       "4         539  smelly vagina bluerasberry why don t you be a ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  i m sorry i m not an admin i will give you thr...   \n",
       "30104     527  i m sorry i m not an admin i will give you thr...   \n",
       "30105     352  wow are you out of your mind how wa my edit on...   \n",
       "30106     311  wow are you out of your mind how wa my edit on...   \n",
       "30107      54  wow are you out of your mind how wa my edit on...   \n",
       "\n",
       "                                              more_toxic  \n",
       "0      what wher is your sexy pic gone from your main...  \n",
       "1      daphne guinness top of the mornin my favourite...  \n",
       "2      atom you don t believe actual photo of masturb...  \n",
       "3      you seem to have sand in your vagina might wan...  \n",
       "4                     hey way to support nazi you racist  \n",
       "...                                                  ...  \n",
       "30103                             get out my large penis  \n",
       "30104                             get out my large penis  \n",
       "30105                       piss off you slant eyed gook  \n",
       "30106                       piss off you slant eyed gook  \n",
       "30107                       piss off you slant eyed gook  \n",
       "\n",
       "[30108 rows x 3 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "cef1173d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7537 7537\n"
     ]
    }
   ],
   "source": [
    "print(len(df), len(replacement_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5054571d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment_coeff</th>\n",
       "      <th>tfidf_scores</th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_rate</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[674.1232445085009, 674.1232445085009, 572.923...</td>\n",
       "      <td>lmao_what weak_threat i_havent been_banned yet...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2392</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[4617.2824966335675, 4617.2824966335675, 4617....</td>\n",
       "      <td>bark_bark bark_bark bark_bark bark_bark bark_b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2921</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[9.234564993267135, 7.848270632147245]</td>\n",
       "      <td>dominicanyou suck_dick</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3028</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1194.905616415079, 1310.6611955685898, 1465.6...</td>\n",
       "      <td>fuck_u bitch_fuck u_bitch fuck_u bitch_fuck u_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1836.452776113066, 1836.452776113066, 1836.45...</td>\n",
       "      <td>bullshit_bullshit bullshit_bullshit bullshit_b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3760</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[1979.0048247016605, 1979.0048247016605, 1979....</td>\n",
       "      <td>u_suck u_suck u_suck u_suck u_suck u_suck u_su...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4130</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[8.829099885158971, 9.234564993267135]</td>\n",
       "      <td>penis_penis pensis</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[4617.2824966335675, 4617.2824966335675, 4617....</td>\n",
       "      <td>shit_shit shit_shit shit_shit shit_shit shit_s...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4571</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[4617.2824966335675, 4617.2824966335675, 4617....</td>\n",
       "      <td>super_gay super_gay super_gay super_gay super_...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4735</th>\n",
       "      <td>[0, 0, 0]</td>\n",
       "      <td>[7.1551234515873, 7.848270632147245, 8.8290998...</td>\n",
       "      <td>fuck_u bitch_fuck u_bitch</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[17.082835625414383, 17.082835625414383]</td>\n",
       "      <td>faggot_faggot faggot_faggot</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2096.2462534716396, 2096.2462534716396, 2096....</td>\n",
       "      <td>securityfuck_homeland securityfuck_homeland se...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5416</th>\n",
       "      <td>[0, 0, 0, 0]</td>\n",
       "      <td>[9.234564993267135, 8.829099885158971, 9.23456...</td>\n",
       "      <td>gur es whzat your_retarded</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5417</th>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>[8.829099885158971, 7.730487596490861]</td>\n",
       "      <td>ballsack your_retarded</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>[2724.1966730138047, 2724.1966730138047, 2724....</td>\n",
       "      <td>aid_aid aid_aid aid_aid aidsaids_aid aid_aid a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        sentiment_coeff  \\\n",
       "2236  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2392  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "2921                                             [0, 0]   \n",
       "3028  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3132  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "3760  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4130                                             [0, 0]   \n",
       "4174  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4571  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "4735                                          [0, 0, 0]   \n",
       "4961                                             [0, 0]   \n",
       "4998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "5416                                       [0, 0, 0, 0]   \n",
       "5417                                             [0, 0]   \n",
       "5543  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
       "\n",
       "                                           tfidf_scores  \\\n",
       "2236  [674.1232445085009, 674.1232445085009, 572.923...   \n",
       "2392  [4617.2824966335675, 4617.2824966335675, 4617....   \n",
       "2921             [9.234564993267135, 7.848270632147245]   \n",
       "3028  [1194.905616415079, 1310.6611955685898, 1465.6...   \n",
       "3132  [1836.452776113066, 1836.452776113066, 1836.45...   \n",
       "3760  [1979.0048247016605, 1979.0048247016605, 1979....   \n",
       "4130             [8.829099885158971, 9.234564993267135]   \n",
       "4174  [4617.2824966335675, 4617.2824966335675, 4617....   \n",
       "4571  [4617.2824966335675, 4617.2824966335675, 4617....   \n",
       "4735  [7.1551234515873, 7.848270632147245, 8.8290998...   \n",
       "4961           [17.082835625414383, 17.082835625414383]   \n",
       "4998  [2096.2462534716396, 2096.2462534716396, 2096....   \n",
       "5416  [9.234564993267135, 8.829099885158971, 9.23456...   \n",
       "5417             [8.829099885158971, 7.730487596490861]   \n",
       "5543  [2724.1966730138047, 2724.1966730138047, 2724....   \n",
       "\n",
       "                                               sentence  sentiment  \\\n",
       "2236  lmao_what weak_threat i_havent been_banned yet...          1   \n",
       "2392  bark_bark bark_bark bark_bark bark_bark bark_b...          1   \n",
       "2921                             dominicanyou suck_dick          1   \n",
       "3028  fuck_u bitch_fuck u_bitch fuck_u bitch_fuck u_...          1   \n",
       "3132  bullshit_bullshit bullshit_bullshit bullshit_b...          1   \n",
       "3760  u_suck u_suck u_suck u_suck u_suck u_suck u_su...          1   \n",
       "4130                                 penis_penis pensis          1   \n",
       "4174  shit_shit shit_shit shit_shit shit_shit shit_s...          1   \n",
       "4571  super_gay super_gay super_gay super_gay super_...          1   \n",
       "4735                          fuck_u bitch_fuck u_bitch          1   \n",
       "4961                        faggot_faggot faggot_faggot          1   \n",
       "4998  securityfuck_homeland securityfuck_homeland se...          1   \n",
       "5416                         gur es whzat your_retarded          1   \n",
       "5417                             ballsack your_retarded          1   \n",
       "5543  aid_aid aid_aid aid_aid aidsaids_aid aid_aid a...          1   \n",
       "\n",
       "      sentiment_rate  prediction  \n",
       "2236             0.0           0  \n",
       "2392             0.0           0  \n",
       "2921             0.0           0  \n",
       "3028             0.0           0  \n",
       "3132             0.0           0  \n",
       "3760             0.0           0  \n",
       "4130             0.0           0  \n",
       "4174             0.0           0  \n",
       "4571             0.0           0  \n",
       "4735             0.0           0  \n",
       "4961             0.0           0  \n",
       "4998             0.0           0  \n",
       "5416             0.0           0  \n",
       "5417             0.0           0  \n",
       "5543             0.0           0  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df[replacement_df.sentiment_rate==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d19d05ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       gjalexei you asked about whether there is an a...\n",
       "1       look_like be have an abuser can you please loo...\n",
       "2       i confess to having complete and apparently bl...\n",
       "3       freud s idea are certainly much discussed toda...\n",
       "4       it is not just you this is a laundry list of s...\n",
       "                              ...                        \n",
       "7532                          go_away you annoying vandal\n",
       "7533                                this user is a vandal\n",
       "7534    sorry to sound like a pain but one by followin...\n",
       "7535    well it s pretty fucking irrelevant now i_m un...\n",
       "7536    the team name is great britain and northern ir...\n",
       "Name: sentence, Length: 7537, dtype: object"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df[\"sentence\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "e930e4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: sentiment_rate, dtype: float64)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replacement_df.loc[replacement_df[\"sentence\"] == \"article suck woo woo wooooooo\", 'sentiment_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "da2e83b5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot convert the series to <class 'float'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10332/2999125338.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplacement_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mreplacement_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"sentence\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"article suck woo woo wooooooo\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sentiment_rate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mconverter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"cannot convert the series to {converter}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"__{converter.__name__}__\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot convert the series to <class 'float'>"
     ]
    }
   ],
   "source": [
    "float(replacement_df.loc[replacement_df[\"sentence\"] == \"article suck woo woo wooooooo\", 'sentiment_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8da1a999",
   "metadata": {},
   "outputs": [],
   "source": [
    "less_toxic_score=[]\n",
    "for i in vd[\"less_toxic\"]:\n",
    "    less_toxic_score.append(replacement_df.loc[replacement_df[\"sentence\"] == i, 'sentiment_rate'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3284ba46",
   "metadata": {},
   "outputs": [],
   "source": [
    "more_toxic_score=[]\n",
    "for i in vd[\"more_toxic\"]:\n",
    "    more_toxic_score.append(replacement_df.loc[replacement_df[\"sentence\"] == i, 'sentiment_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2b57dfb7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object of type 'numpy.float64' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10332/4264109850.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mless_toxic_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mless_toxic_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m         \u001b[0mless_toxic_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mless_toxic_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mless_toxic_score\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'numpy.float64' has no len()"
     ]
    }
   ],
   "source": [
    "for i in range(len(less_toxic_score)):\n",
    "    if len(less_toxic_score[i])==0:\n",
    "        less_toxic_score[i]=0.0\n",
    "    else:\n",
    "        less_toxic_score[i]=less_toxic_score[i].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "06190dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(more_toxic_score)):\n",
    "    if len(more_toxic_score[i])==0:\n",
    "        more_toxic_score[i]=0.0\n",
    "    else:\n",
    "        more_toxic_score[i]=more_toxic_score[i].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8db371ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[\"less_toxic_score\"]=less_toxic_score\n",
    "vd[\"more_toxic_score\"]=more_toxic_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6c2c4f56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>less_toxic_score</th>\n",
       "      <th>more_toxic_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>this article suck woo woo wooooooo</td>\n",
       "      <td>what wher is your sexy pic gone from your main...</td>\n",
       "      <td>502.455108</td>\n",
       "      <td>65.205077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>188</td>\n",
       "      <td>and yes people should recognize that but they ...</td>\n",
       "      <td>daphne guinness top of the mornin my favourite...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>82</td>\n",
       "      <td>western medium yup because every crime in the ...</td>\n",
       "      <td>atom you don t believe actual photo of masturb...</td>\n",
       "      <td>365.270493</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>347</td>\n",
       "      <td>and you removed it you numbskull i don t care ...</td>\n",
       "      <td>you seem to have sand in your vagina might wan...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-219.690495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539</td>\n",
       "      <td>smelly vagina bluerasberry why don t you be a ...</td>\n",
       "      <td>hey way to support nazi you racist</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-33.568555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30103</th>\n",
       "      <td>461</td>\n",
       "      <td>i m sorry i m not an admin i will give you thr...</td>\n",
       "      <td>get out my large penis</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.762924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30104</th>\n",
       "      <td>527</td>\n",
       "      <td>i m sorry i m not an admin i will give you thr...</td>\n",
       "      <td>get out my large penis</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.762924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30105</th>\n",
       "      <td>352</td>\n",
       "      <td>wow are you out of your mind how wa my edit on...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399.228578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30106</th>\n",
       "      <td>311</td>\n",
       "      <td>wow are you out of your mind how wa my edit on...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399.228578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30107</th>\n",
       "      <td>54</td>\n",
       "      <td>wow are you out of your mind how wa my edit on...</td>\n",
       "      <td>piss off you slant eyed gook</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>399.228578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30108 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313                 this article suck woo woo wooooooo   \n",
       "1         188  and yes people should recognize that but they ...   \n",
       "2          82  western medium yup because every crime in the ...   \n",
       "3         347  and you removed it you numbskull i don t care ...   \n",
       "4         539  smelly vagina bluerasberry why don t you be a ...   \n",
       "...       ...                                                ...   \n",
       "30103     461  i m sorry i m not an admin i will give you thr...   \n",
       "30104     527  i m sorry i m not an admin i will give you thr...   \n",
       "30105     352  wow are you out of your mind how wa my edit on...   \n",
       "30106     311  wow are you out of your mind how wa my edit on...   \n",
       "30107      54  wow are you out of your mind how wa my edit on...   \n",
       "\n",
       "                                              more_toxic  less_toxic_score  \\\n",
       "0      what wher is your sexy pic gone from your main...        502.455108   \n",
       "1      daphne guinness top of the mornin my favourite...          0.000000   \n",
       "2      atom you don t believe actual photo of masturb...        365.270493   \n",
       "3      you seem to have sand in your vagina might wan...          0.000000   \n",
       "4                     hey way to support nazi you racist          0.000000   \n",
       "...                                                  ...               ...   \n",
       "30103                             get out my large penis          0.000000   \n",
       "30104                             get out my large penis          0.000000   \n",
       "30105                       piss off you slant eyed gook          0.000000   \n",
       "30106                       piss off you slant eyed gook          0.000000   \n",
       "30107                       piss off you slant eyed gook          0.000000   \n",
       "\n",
       "       more_toxic_score  \n",
       "0             65.205077  \n",
       "1              0.000000  \n",
       "2              0.000000  \n",
       "3           -219.690495  \n",
       "4            -33.568555  \n",
       "...                 ...  \n",
       "30103         56.762924  \n",
       "30104         56.762924  \n",
       "30105        399.228578  \n",
       "30106        399.228578  \n",
       "30107        399.228578  \n",
       "\n",
       "[30108 rows x 5 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "65049915",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'less_toxic_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3360\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3361\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'less_toxic_score'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10332/291068227.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"less_toxic_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m<\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"more_toxic_score\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 942\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m         \u001b[1;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3361\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3362\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3363\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3365\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhasnans\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'less_toxic_score'"
     ]
    }
   ],
   "source": [
    "scores=[]\n",
    "for index, row in vd.iterrows():\n",
    "    if row[\"less_toxic_score\"]<row[\"more_toxic_score\"]:\n",
    "        scores.append(1)\n",
    "    else:\n",
    "        scores.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "dc4d352d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[\"scores\"]=scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "171b5626",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>worker</th>\n",
       "      <th>less_toxic</th>\n",
       "      <th>more_toxic</th>\n",
       "      <th>less_toxic_score</th>\n",
       "      <th>more_toxic_score</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313</td>\n",
       "      <td>this article suck woo woo wooooooo</td>\n",
       "      <td>what wher is your sexy pic gone from your main...</td>\n",
       "      <td>502.455108</td>\n",
       "      <td>65.205077</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>18</td>\n",
       "      <td>yeah this is pretty lame</td>\n",
       "      <td>fuck you it war now asshole</td>\n",
       "      <td>-120.688666</td>\n",
       "      <td>-12.866763</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>382</td>\n",
       "      <td>you think im stupid or smth quit using this ip...</td>\n",
       "      <td>im a fucking cunt</td>\n",
       "      <td>-111.332178</td>\n",
       "      <td>-27.922719</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>204</td>\n",
       "      <td>no repsonse just carry on destroying the wiki ...</td>\n",
       "      <td>and this is nothing but a bald faced strawmann...</td>\n",
       "      <td>-172.691531</td>\n",
       "      <td>-47.551315</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>268</td>\n",
       "      <td>too cool please please please get a life shoul...</td>\n",
       "      <td>i just re read promise of witch king i had my ...</td>\n",
       "      <td>-543.076493</td>\n",
       "      <td>1961.761926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30007</th>\n",
       "      <td>170</td>\n",
       "      <td>join the mike garcia brigade together we shall...</td>\n",
       "      <td>pharisee the context in sotah a list of false ...</td>\n",
       "      <td>608.431671</td>\n",
       "      <td>2283.092523</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30024</th>\n",
       "      <td>733</td>\n",
       "      <td>hello john a you decided to delete my very inf...</td>\n",
       "      <td>daylans a looser and ik kant spel</td>\n",
       "      <td>41.648245</td>\n",
       "      <td>-93.130547</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30049</th>\n",
       "      <td>465</td>\n",
       "      <td>support stop the pov of nationalist editor</td>\n",
       "      <td>your a fucking faggot you internet thug get of...</td>\n",
       "      <td>77.772212</td>\n",
       "      <td>-65.676708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30050</th>\n",
       "      <td>609</td>\n",
       "      <td>support stop the pov of nationalist editor</td>\n",
       "      <td>your a fucking faggot you internet thug get of...</td>\n",
       "      <td>77.772212</td>\n",
       "      <td>-65.676708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30051</th>\n",
       "      <td>682</td>\n",
       "      <td>support stop the pov of nationalist editor</td>\n",
       "      <td>your a fucking faggot you internet thug get of...</td>\n",
       "      <td>77.772212</td>\n",
       "      <td>-65.676708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       worker                                         less_toxic  \\\n",
       "0         313                 this article suck woo woo wooooooo   \n",
       "24         18                           yeah this is pretty lame   \n",
       "57        382  you think im stupid or smth quit using this ip...   \n",
       "59        204  no repsonse just carry on destroying the wiki ...   \n",
       "91        268  too cool please please please get a life shoul...   \n",
       "...       ...                                                ...   \n",
       "30007     170  join the mike garcia brigade together we shall...   \n",
       "30024     733  hello john a you decided to delete my very inf...   \n",
       "30049     465         support stop the pov of nationalist editor   \n",
       "30050     609         support stop the pov of nationalist editor   \n",
       "30051     682         support stop the pov of nationalist editor   \n",
       "\n",
       "                                              more_toxic  less_toxic_score  \\\n",
       "0      what wher is your sexy pic gone from your main...        502.455108   \n",
       "24                           fuck you it war now asshole       -120.688666   \n",
       "57                                     im a fucking cunt       -111.332178   \n",
       "59     and this is nothing but a bald faced strawmann...       -172.691531   \n",
       "91     i just re read promise of witch king i had my ...       -543.076493   \n",
       "...                                                  ...               ...   \n",
       "30007  pharisee the context in sotah a list of false ...        608.431671   \n",
       "30024                  daylans a looser and ik kant spel         41.648245   \n",
       "30049  your a fucking faggot you internet thug get of...         77.772212   \n",
       "30050  your a fucking faggot you internet thug get of...         77.772212   \n",
       "30051  your a fucking faggot you internet thug get of...         77.772212   \n",
       "\n",
       "       more_toxic_score  scores  \n",
       "0             65.205077       1  \n",
       "24           -12.866763       0  \n",
       "57           -27.922719       0  \n",
       "59           -47.551315       0  \n",
       "91          1961.761926       0  \n",
       "...                 ...     ...  \n",
       "30007       2283.092523       0  \n",
       "30024        -93.130547       1  \n",
       "30049        -65.676708       1  \n",
       "30050        -65.676708       1  \n",
       "30051        -65.676708       1  \n",
       "\n",
       "[1081 rows x 6 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "97807a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.811047\n",
       "1    0.188953\n",
       "Name: scores, dtype: float64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd[\"scores\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "e8413f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = vd[vd.less_toxic_score != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "4de94479",
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = vd[vd.more_toxic_score != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2d92af1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.562442\n",
       "0    0.437558\n",
       "Name: scores, dtype: float64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vd[\"scores\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "53c28799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1081"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0134975",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
